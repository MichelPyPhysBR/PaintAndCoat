import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import networkx as nx
from collections import Counter, defaultdict
import re
import warnings
import itertools
warnings.filterwarnings('ignore')

# Tentar importar bibliotecas opcionais
try:
    from scipy.stats import powerlaw
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.cluster import KMeans
    from sklearn.decomposition import PCA
    ADVANCED_LIBS = True
except ImportError:
    ADVANCED_LIBS = False
    st.warning("‚ö†Ô∏è Algumas bibliotecas avan√ßadas n√£o est√£o dispon√≠veis. Instale com: pip install scipy scikit-learn")

try:
    from wordcloud import WordCloud
    WORDCLOUD_AVAILABLE = True
except ImportError:
    WORDCLOUD_AVAILABLE = False

# Configura√ß√µes da p√°gina
st.set_page_config(
    page_title="Dashboard Bibliom√©trico Avan√ßado - Tintas Sustent√°veis",
    page_icon="üî¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personalizado
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1e3a8a;
        text-align: center;
        margin-bottom: 2rem;
        font-weight: bold;
    }
    .section-header {
        font-size: 1.8rem;
        color: #1e40af;
        margin-top: 2rem;
        margin-bottom: 1rem;
        border-bottom: 2px solid #3b82f6;
        padding-bottom: 0.5rem;
    }
    .metric-card {
        background-color: #f8fafc;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #3b82f6;
        margin: 1rem 0;
    }
    .explanation-box {
        background-color: #f0f9ff;
        padding: 1.5rem;
        border-radius: 0.5rem;
        border: 1px solid #0ea5e9;
        margin: 1rem 0;
    }
    .quadrant-box {
        background-color: #fefce8;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #eab308;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_data
def load_and_process_data():
    """Carrega e processa os dados reais do Scopus"""
    try:
        df = pd.read_csv('scopus.csv', encoding='utf-8')
        
        # Renomear colunas
        column_mapping = {
            'Cited by': 'Citations',
            'Author Keywords': 'Author_Keywords',
            'Index Keywords': 'Index_Keywords',
            'Source title': 'Journal',
            'Document Type': 'Document_Type'
        }
        df = df.rename(columns=column_mapping)
        
        # Processamento
        df['Citations'] = pd.to_numeric(df['Citations'], errors='coerce').fillna(0).astype(int)
        df['Year'] = pd.to_numeric(df['Year'], errors='coerce').fillna(0).astype(int)
        df['Author_Keywords'] = df['Author_Keywords'].fillna('')
        df['Index_Keywords'] = df['Index_Keywords'].fillna('')
        df['Journal'] = df['Journal'].fillna('Unknown')
        df['Authors'] = df['Authors'].fillna('')
        df['Affiliations'] = df['Affiliations'].fillna('') if 'Affiliations' in df.columns else ''
        
        df = df[df['Year'] > 1900]
        st.success(f"‚úÖ Dados carregados: {len(df)} artigos do Scopus")
        
    except FileNotFoundError:
        st.error("‚ùå Arquivo scopus.csv n√£o encontrado! Usando dados sint√©ticos.")
        df = create_synthetic_data()
    except Exception as e:
        st.error(f"‚ùå Erro: {e}. Usando dados sint√©ticos.")
        df = create_synthetic_data()
    
    return df

def create_synthetic_data():
    """Cria dados sint√©ticos para demonstra√ß√£o"""
    np.random.seed(42)
    n_papers = 800
    
    years = np.random.choice(range(2015, 2025), n_papers, 
                            p=[0.05, 0.08, 0.1, 0.12, 0.15, 0.18, 0.15, 0.1, 0.05, 0.02])
    citations = np.random.exponential(3, n_papers).astype(int)
    
    # Keywords tem√°ticas mais realistas
    themes = {
        'sustainability': ['sustainable coating', 'eco-friendly', 'green chemistry', 'bio-based', 'renewable'],
        'nanotechnology': ['nanoparticles', 'nanomaterials', 'nanocomposite', 'graphene', 'carbon nanotubes'],
        'functionality': ['self-healing', 'antimicrobial', 'anti-corrosion', 'photocatalytic', 'smart coating'],
        'materials': ['polymer', 'metal oxide', 'titanium dioxide', 'zinc oxide', 'silica'],
        'applications': ['automotive', 'marine', 'construction', 'aerospace', 'biomedical']
    }
    
    authors_pool = [
        "Zhang, L.", "Smith, J.", "Wang, Y.", "Brown, M.", "Li, X.",
        "Johnson, R.", "Chen, W.", "Davis, S.", "Liu, H.", "Wilson, K.",
        "Garcia, A.", "Martinez, C.", "Anderson, P.", "Taylor, D.", "Thomas, J."
    ]
    
    journals_pool = [
        "Progress in Organic Coatings", "Surface and Coatings Technology", 
        "Journal of Coatings Technology", "Applied Surface Science",
        "Green Chemistry", "Journal of Cleaner Production", "ACS Applied Materials"
    ]
    
    data = []
    for i in range(n_papers):
        # Selecionar tema principal
        main_theme = np.random.choice(list(themes.keys()))
        theme_keywords = themes[main_theme]
        
        # Adicionar keywords de outros temas (co-ocorr√™ncia)
        all_keywords = theme_keywords.copy()
        for other_theme in themes.keys():
            if other_theme != main_theme and np.random.random() < 0.3:
                all_keywords.extend(np.random.choice(themes[other_theme], 1))
        
        keywords_str = "; ".join(np.random.choice(all_keywords, 
                                                min(len(all_keywords), np.random.randint(3, 7)), 
                                                replace=False))
        
        # Autores
        n_authors = np.random.choice([1, 2, 3, 4, 5], p=[0.2, 0.3, 0.3, 0.15, 0.05])
        authors = np.random.choice(authors_pool, n_authors, replace=False)
        authors_str = "; ".join(authors)
        
        data.append({
            'Title': f"Sustainable Coating Research {i+1}: {theme_keywords[0].title()}",
            'Authors': authors_str,
            'Year': years[i],
            'Citations': citations[i],
            'Journal': np.random.choice(journals_pool),
            'Author_Keywords': keywords_str,
            'Index_Keywords': keywords_str,
            'Affiliations': f"University {chr(65 + i % 26)}, {np.random.choice(['USA', 'China', 'Germany', 'Japan', 'UK'])}"
        })
    
    return pd.DataFrame(data)

@st.cache_data
def extract_keywords_with_cooccurrence(df):
    """Extrai palavras-chave e calcula co-ocorr√™ncia"""
    all_keywords = []
    keyword_pairs = []
    
    for idx, row in df.iterrows():
        paper_keywords = []
        
        # Combinar author e index keywords
        for kw_col in ['Author_Keywords', 'Index_Keywords']:
            if pd.notna(row[kw_col]) and str(row[kw_col]).strip():
                kws = [kw.strip().lower() for kw in str(row[kw_col]).split(';')]
                paper_keywords.extend(kws)
        
        # Limpar e deduplicate
        paper_keywords = [kw for kw in set(paper_keywords) if kw and len(kw) > 2]
        
        # Adicionar keywords individuais
        for kw in paper_keywords:
            all_keywords.append({
                'Paper_ID': idx,
                'Keyword': kw,
                'Year': row['Year'],
                'Citations': row['Citations']
            })
        
        # Calcular pares (co-ocorr√™ncia)
        for pair in itertools.combinations(paper_keywords, 2):
            keyword_pairs.append({
                'Keyword1': pair[0],
                'Keyword2': pair[1],
                'Year': row['Year'],
                'Paper_ID': idx
            })
    
    keywords_df = pd.DataFrame(all_keywords)
    cooccurrence_df = pd.DataFrame(keyword_pairs)
    
    return keywords_df, cooccurrence_df

def calculate_h_index(citations_sorted):
    """Calcula √≠ndice H"""
    h_index = 0
    for i, citations in enumerate(citations_sorted, 1):
        if citations >= i:
            h_index = i
        else:
            break
    return h_index

def analyze_lotka_law(author_stats):
    """Analisa Lei de Lotka (distribui√ß√£o de produtividade)"""
    if len(author_stats) == 0:
        return None, None, None
        
    productivity = author_stats['Papers_Count'].values
    unique_counts = np.unique(productivity)
    freq = [np.sum(productivity == count) for count in unique_counts]
    
    # Ajuste da Lei de Lotka: f(x) = C / x^Œ±
    # Log transform: log(f) = log(C) - Œ± * log(x)
    try:
        log_x = np.log(unique_counts)
        log_y = np.log(freq)
        
        # Regress√£o linear no espa√ßo log
        coef = np.polyfit(log_x, log_y, 1)
        alpha = -coef[0]  # Expoente de Lotka
        C = np.exp(coef[1])  # Constante
        
        return unique_counts, freq, alpha
    except:
        return unique_counts, freq, None

def create_thematic_evolution(keywords_df):
    """Cria an√°lise de evolu√ß√£o tem√°tica"""
    if len(keywords_df) == 0:
        return pd.DataFrame()
        
    # Agrupar por palavra-chave e ano
    evolution = keywords_df.groupby(['Keyword', 'Year']).agg({
        'Paper_ID': 'count',
        'Citations': 'sum'
    }).reset_index()
    
    evolution.columns = ['Keyword', 'Year', 'Frequency', 'Citations']
    
    # Calcular tend√™ncia (slope)
    trend_data = []
    for keyword in evolution['Keyword'].unique():
        kw_data = evolution[evolution['Keyword'] == keyword]
        if len(kw_data) >= 3:  # M√≠nimo 3 anos
            try:
                slope = np.polyfit(kw_data['Year'], kw_data['Frequency'], 1)[0]
                total_freq = kw_data['Frequency'].sum()
                trend_data.append({
                    'Keyword': keyword,
                    'Trend': slope,
                    'Total_Frequency': total_freq,
                    'Total_Citations': kw_data['Citations'].sum()
                })
            except:
                continue
    
    return pd.DataFrame(trend_data)

def create_thematic_map(keywords_df, cooccurrence_df):
    """Cria mapa tem√°tico com quadrantes"""
    if len(keywords_df) == 0:
        return pd.DataFrame()
        
    # Calcular centralidade (co-ocorr√™ncia) e densidade
    keyword_stats = keywords_df.groupby('Keyword').agg({
        'Paper_ID': 'count',
        'Citations': 'sum'
    }).reset_index()
    keyword_stats.columns = ['Keyword', 'Frequency', 'Citations']
    
    # Centralidade: quantas vezes aparece com outras palavras
    centrality = {}
    for keyword in keyword_stats['Keyword']:
        cooc_count = len(cooccurrence_df[
            (cooccurrence_df['Keyword1'] == keyword) | 
            (cooccurrence_df['Keyword2'] == keyword)
        ])
        centrality[keyword] = cooc_count
    
    keyword_stats['Centrality'] = keyword_stats['Keyword'].map(centrality).fillna(0)
    keyword_stats['Density'] = keyword_stats['Citations'] / keyword_stats['Frequency']
    
    # Normalizar para classifica√ß√£o em quadrantes
    if len(keyword_stats) > 0 and keyword_stats['Centrality'].std() > 0:
        keyword_stats['Centrality_Norm'] = (keyword_stats['Centrality'] - keyword_stats['Centrality'].mean()) / keyword_stats['Centrality'].std()
        keyword_stats['Density_Norm'] = (keyword_stats['Density'] - keyword_stats['Density'].mean()) / keyword_stats['Density'].std()
        
        # Classificar em quadrantes
        def classify_quadrant(row):
            if row['Centrality_Norm'] > 0 and row['Density_Norm'] > 0:
                return 'Motor Themes'
            elif row['Centrality_Norm'] > 0 and row['Density_Norm'] <= 0:
                return 'Basic Themes'
            elif row['Centrality_Norm'] <= 0 and row['Density_Norm'] > 0:
                return 'Niche Themes'
            else:
                return 'Emerging/Declining'
        
        keyword_stats['Quadrant'] = keyword_stats.apply(classify_quadrant, axis=1)
    
    return keyword_stats

def create_collaboration_network(df):
    """Cria rede de colabora√ß√£o entre autores"""
    author_pairs = []
    
    for _, row in df.iterrows():
        if pd.notna(row['Authors']):
            authors = [a.strip() for a in str(row['Authors']).split(';')]
            if len(authors) > 1:
                for pair in itertools.combinations(authors, 2):
                    author_pairs.append(pair)
    
    # Contar colabora√ß√µes
    collab_counts = Counter(author_pairs)
    
    # Criar rede
    G = nx.Graph()
    for (author1, author2), weight in collab_counts.items():
        if weight >= 2:  # Filtrar colabora√ß√µes m√≠nimas
            G.add_edge(author1, author2, weight=weight)
    
    return G

def safe_divide(a, b):
    """Divis√£o segura para evitar divis√£o por zero"""
    return a / b if b != 0 else 0

def main():
    st.markdown('<div class="main-header">üî¨ Dashboard Bibliom√©trico Avan√ßado<br>Tintas e Revestimentos Sustent√°veis</div>', unsafe_allow_html=True)
    
    # Carregamento dos dados
    with st.spinner("Carregando dados e preparando an√°lises avan√ßadas..."):
        df = load_and_process_data()
        keywords_df, cooccurrence_df = extract_keywords_with_cooccurrence(df)
    
    # Calcular m√©tricas principais uma vez para uso global
    h_index = calculate_h_index(df['Citations'].sort_values(ascending=False))
    
    # Calcular taxa de colabora√ß√£o de forma segura
    multi_author_papers = 0
    for authors_str in df['Authors'].dropna():
        authors = [a.strip() for a in str(authors_str).split(';')]
        if len(authors) > 1:
            multi_author_papers += 1
    
    collaboration_rate = safe_divide(multi_author_papers, len(df))
    
    # Sidebar
    st.sidebar.header("üìã An√°lises Bibliom√©tricas")
    st.sidebar.markdown(f"""
    **Dataset:** {len(df)} artigos
    **Per√≠odo:** {df['Year'].min()}-{df['Year'].max()}
    **Keywords:** {len(keywords_df['Keyword'].unique()) if len(keywords_df) > 0 else 0} √∫nicas
    **Co-ocorr√™ncias:** {len(cooccurrence_df)} pares
    """)
    
    # Sele√ß√£o de an√°lises
    analysis_option = st.sidebar.selectbox(
        "Escolha a an√°lise:",
        [
            "1. Dados Gerais",
            "2. Evolu√ß√£o Tem√°tica", 
            "3. Mapa Tem√°tico",
            "4. Trend Topics",
            "5. Co-ocorr√™ncia de Keywords",
            "6. Redes de Colabora√ß√£o",
            "7. An√°lise de Co-cita√ß√£o",
            "8. Top Papers (Cita√ß√µes)",
            "9. Lei de Lotka (Autores)"
        ]
    )
    
    # ===============================
    # 1. DADOS GERAIS
    # ===============================
    if "1. Dados Gerais" in analysis_option:
        st.markdown('<div class="section-header">üìä 1. Dados Gerais & An√°lise Descritiva</div>', unsafe_allow_html=True)
        
        # M√©tricas principais
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Total Artigos", f"{len(df):,}")
        with col2:
            st.metric("Total Cita√ß√µes", f"{df['Citations'].sum():,}")
        with col3:
            unique_authors = len(set([a.strip() for authors in df['Authors'].dropna() for a in str(authors).split(';') if a.strip()]))
            st.metric("Autores √önicos", f"{unique_authors:,}")
        with col4:
            st.metric("√çndice H", f"{h_index}")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Taxa Colabora√ß√£o", f"{collaboration_rate*100:.1f}%")
        with col2:
            st.metric("Per√≠odo", f"{df['Year'].min()}-{df['Year'].max()}")
        with col3:
            st.metric("Revistas √önicas", f"{df['Journal'].nunique()}")
        with col4:
            avg_citations = df['Citations'].mean()
            st.metric("M√©dia Cita√ß√µes", f"{avg_citations:.1f}")
        
        st.markdown("""
        <div class="explanation-box">
        <h4>üìà Por que usar Dados Gerais?</h4>
        <ul>
            <li><strong>Panorama b√°sico:</strong> N√∫mero total de documentos, autores e cita√ß√µes</li>
            <li><strong>Evolu√ß√£o temporal:</strong> Mostra crescimento da produ√ß√£o cient√≠fica anual</li>
            <li><strong>Principais fontes:</strong> Identifica jornais e pa√≠ses mais produtivos</li>
            <li><strong>Base quantitativa:</strong> Fundamenta introdu√ß√£o e metodologia com estat√≠sticas</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)
        
        # Produ√ß√£o anual
        yearly_prod = df['Year'].value_counts().sort_index()
        fig_yearly = px.line(x=yearly_prod.index, y=yearly_prod.values, 
                           title="Produ√ß√£o Cient√≠fica Anual", markers=True)
        fig_yearly.update_layout(xaxis_title="Ano", yaxis_title="N√∫mero de Artigos")
        st.plotly_chart(fig_yearly, use_container_width=True)
        
        # Top journals
        top_journals = df['Journal'].value_counts().head(10)
        fig_journals = px.bar(y=top_journals.index, x=top_journals.values, orientation='h',
                            title="Top 10 Revistas Mais Produtivas")
        fig_journals.update_layout(yaxis_title="Revista", xaxis_title="N√∫mero de Artigos")
        st.plotly_chart(fig_journals, use_container_width=True)
        
        # Explica√ß√£o dos resultados
        st.markdown("""
        <div class="explanation-box">
        <h4>üîç Como Interpretar os Resultados:</h4>
        <ul>
            <li><strong>Crescimento anual:</strong> Tend√™ncia ascendente indica √°rea em expans√£o e oportunidades de financiamento</li>
            <li><strong>Top revistas:</strong> Identifica onde publicar e quais acompanhar para estar atualizado</li>
            <li><strong>Picos de produ√ß√£o:</strong> Podem coincidir com marcos regulat√≥rios (ex: normas ambientais)</li>
            <li><strong>Distribui√ß√£o geogr√°fica:</strong> Revela centros de expertise para parcerias</li>
        </ul>
        <p><strong>üí° A√ß√£o recomendada:</strong> Foque nas revistas top 5 para submiss√µes e monitore tend√™ncias anuais para timing de projetos.</p>
        </div>
        """, unsafe_allow_html=True)
    
    # ===============================
    # 2. EVOLU√á√ÉO TEM√ÅTICA
    # ===============================
    elif "2. Evolu√ß√£o Tem√°tica" in analysis_option:
        st.markdown('<div class="section-header">üå± 2. Evolu√ß√£o Tem√°tica</div>', unsafe_allow_html=True)
        
        st.markdown("""
        <div class="explanation-box">
        <h4>üéØ Por que usar Evolu√ß√£o Tem√°tica?</h4>
        <ul>
            <li><strong>Emerg√™ncia de temas:</strong> Identifica como temas amadurecem ou declinam</li>
            <li><strong>Novos materiais:</strong> Rastreia √≥xidos met√°licos nanom√©tricos, autorrepara√ß√£o</li>
            <li><strong>Lacunas de pesquisa:</strong> Fornece insights para √°reas promissoras</li>
            <li><strong>Antecipa√ß√£o:</strong> Permite prever tend√™ncias futuras</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)
        
        evolution_data = create_thematic_evolution(keywords_df)
        
        if len(evolution_data) > 0:
            # Top trending keywords
            trending_up = evolution_data.nlargest(10, 'Trend')
            trending_down = evolution_data.nsmallest(10, 'Trend')
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("üöÄ Temas Emergentes (Trend ‚ÜóÔ∏è)")
                if len(trending_up) > 0:
                    fig_up = px.bar(trending_up, x='Trend', y='Keyword', orientation='h',
                                  color='Total_Citations', title="Keywords com Maior Crescimento")
                    st.plotly_chart(fig_up, use_container_width=True)
            
            with col2:
                st.subheader("üìâ Temas em Decl√≠nio (Trend ‚ÜòÔ∏è)")
                if len(trending_down) > 0:
                    fig_down = px.bar(trending_down, x='Trend', y='Keyword', orientation='h',
                                    color='Total_Citations', title="Keywords em Decl√≠nio")
                    st.plotly_chart(fig_down, use_container_width=True)
            
            # Heatmap de evolu√ß√£o temporal
            st.subheader("üî• Mapa de Calor - Evolu√ß√£o Temporal")
            
            # Preparar dados para heatmap
            keywords_df_year = keywords_df.groupby(['Keyword', 'Year']).size().reset_index(name='Count')
            top_keywords = keywords_df['Keyword'].value_counts().head(20).index
            
            heatmap_data = keywords_df_year[keywords_df_year['Keyword'].isin(top_keywords)]
            if len(heatmap_data) > 0:
                pivot_data = heatmap_data.pivot(index='Keyword', columns='Year', values='Count').fillna(0)
                
                fig_heatmap = px.imshow(pivot_data, 
                                      title="Evolu√ß√£o Temporal das Top 20 Keywords",
                                      color_continuous_scale='Viridis')
                st.plotly_chart(fig_heatmap, use_container_width=True)
            
            # Explica√ß√£o dos resultados
            st.markdown("""
            <div class="explanation-box">
            <h4>üîç Como Interpretar a Evolu√ß√£o Tem√°tica:</h4>
            <ul>
                <li><strong>Temas Emergentes (Trend ‚ÜóÔ∏è):</strong> √Åreas com crescimento acelerado - oportunidades de inova√ß√£o</li>
                <li><strong>Temas em Decl√≠nio (Trend ‚ÜòÔ∏è):</strong> Podem indicar satura√ß√£o ou mudan√ßa de paradigma</li>
                <li><strong>Heatmap temporal:</strong> Cores quentes = alta atividade, cores frias = baixa atividade</li>
                <li><strong>Padr√µes sazonais:</strong> Alguns temas podem ter ciclos relacionados a regulamenta√ß√µes</li>
            </ul>
            <p><strong>üí° Para Tintas Sustent√°veis:</strong></p>
            <ul>
                <li><strong>Se "bio-based" est√° emergente:</strong> Invista em pol√≠meros naturais</li>
                <li><strong>Se "nanoparticles" declina:</strong> Foque em alternativas sustent√°veis</li>
                <li><strong>Timing estrat√©gico:</strong> Entre em temas emergentes antes do pico de competi√ß√£o</li>
            </ul>
            <p><strong>üéØ A√ß√£o recomendada:</strong> Monitore temas com trend positivo consistente por 3+ anos para investimento em P&D.</p>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.warning("‚ö†Ô∏è Dados insuficientes para an√°lise de evolu√ß√£o tem√°tica")
    
    # ===============================
    # 3. MAPA TEM√ÅTICO
    # ===============================
    elif "3. Mapa Tem√°tico" in analysis_option:
        st.markdown('<div class="section-header">üó∫Ô∏è 3. Mapa Tem√°tico</div>', unsafe_allow_html=True)
        
        st.markdown("""
        <div class="explanation-box">
        <h4>üéØ Por que usar Mapa Tem√°tico?</h4>
        <ul>
            <li><strong>Classifica√ß√£o por quadrantes:</strong> Motor, b√°sico, emergente/perif√©rico</li>
            <li><strong>Prioriza√ß√£o:</strong> Diferencia t√≥picos centrais vs explorat√≥rios</li>
            <li><strong>√Åreas consolidadas:</strong> Ex: auto-limpeza vs sensores fotocatal√≠ticos</li>
            <li><strong>Decis√µes estrat√©gicas:</strong> Facilita desenvolvimento e financiamento</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)
        
        thematic_map = create_thematic_map(keywords_df, cooccurrence_df)
        
        if len(thematic_map) > 0 and 'Quadrant' in thematic_map.columns:
            # Scatter plot dos quadrantes
            fig_map = px.scatter(thematic_map, x='Centrality_Norm', y='Density_Norm',
                               size='Frequency', color='Quadrant', hover_name='Keyword',
                               title="Mapa Tem√°tico - Classifica√ß√£o por Quadrantes")
            
            # Adicionar linhas dos quadrantes
            fig_map.add_hline(y=0, line_dash="dash", line_color="gray")
            fig_map.add_vline(x=0, line_dash="dash", line_color="gray")
            
            # Labels dos quadrantes
            fig_map.add_annotation(x=1.5, y=1.5, text="MOTOR THEMES<br>(High Centrality & Density)", 
                                 showarrow=False, bgcolor="rgba(255,255,255,0.8)")
            fig_map.add_annotation(x=1.5, y=-1.5, text="BASIC THEMES<br>(High Centrality, Low Density)", 
                                 showarrow=False, bgcolor="rgba(255,255,255,0.8)")
            fig_map.add_annotation(x=-1.5, y=1.5, text="NICHE THEMES<br>(Low Centrality, High Density)", 
                                 showarrow=False, bgcolor="rgba(255,255,255,0.8)")
            fig_map.add_annotation(x=-1.5, y=-1.5, text="EMERGING/DECLINING<br>(Low Centrality & Density)", 
                                 showarrow=False, bgcolor="rgba(255,255,255,0.8)")
            
            st.plotly_chart(fig_map, use_container_width=True)
            
            # Resumo por quadrante
            quadrant_summary = thematic_map.groupby('Quadrant').agg({
                'Keyword': 'count',
                'Frequency': 'sum',
                'Citations': 'sum'
            }).round(2)
            
            st.subheader("üìä Resumo por Quadrante")
            for quadrant in quadrant_summary.index:
                keywords_in_quad = thematic_map[thematic_map['Quadrant'] == quadrant]['Keyword'].tolist()
                st.markdown(f"""
                <div class="quadrant-box">
                <h4>{quadrant}</h4>
                <p><strong>Keywords ({len(keywords_in_quad)}):</strong> {', '.join(keywords_in_quad[:5])}{'...' if len(keywords_in_quad) > 5 else ''}</p>
                <p><strong>Total Citations:</strong> {quadrant_summary.loc[quadrant, 'Citations']}</p>
                </div>
                """, unsafe_allow_html=True)
            
            # Explica√ß√£o estrat√©gica dos quadrantes
            st.markdown("""
            <div class="explanation-box">
            <h4>üîç Como Interpretar o Mapa Tem√°tico:</h4>
            
            <p><strong>üöÄ MOTOR THEMES (Alta Centralidade + Alta Densidade):</strong></p>
            <ul>
                <li><strong>O que s√£o:</strong> Temas centrais e bem desenvolvidos da √°rea</li>
                <li><strong>Estrat√©gia:</strong> Mantenha investimento para liderar mercado</li>
                <li><strong>Exemplo:</strong> Se "coating performance" est√° aqui, √© √°rea consolidada para inovar</li>
            </ul>
            
            <p><strong>üìö BASIC THEMES (Alta Centralidade + Baixa Densidade):</strong></p>
            <ul>
                <li><strong>O que s√£o:</strong> Temas fundamentais mas pouco explorados</li>
                <li><strong>Estrat√©gia:</strong> Oportunidade de especializa√ß√£o e diferencia√ß√£o</li>
                <li><strong>Exemplo:</strong> "sustainability" pode estar aqui - conceito amplo, pouco espec√≠fico</li>
            </ul>
            
            <p><strong>üéØ NICHE THEMES (Baixa Centralidade + Alta Densidade):</strong></p>
            <ul>
                <li><strong>O que s√£o:</strong> Especializa√ß√µes t√©cnicas espec√≠ficas</li>
                <li><strong>Estrat√©gia:</strong> Nichos rent√°veis para empresas especializadas</li>
                <li><strong>Exemplo:</strong> "marine coatings" - aplica√ß√£o espec√≠fica mas bem desenvolvida</li>
            </ul>
            
            <p><strong>üå± EMERGING/DECLINING (Baixa Centralidade + Baixa Densidade):</strong></p>
            <ul>
                <li><strong>O que s√£o:</strong> Temas nascentes ou em decl√≠nio</li>
                <li><strong>Estrat√©gia:</strong> Monitore emergentes, abandone os em decl√≠nio</li>
                <li><strong>Exemplo:</strong> "smart coatings" pode estar emergindo</li>
            </ul>
            
            <p><strong>üéØ A√ß√£o Estrat√©gica:</strong></p>
            <ul>
                <li><strong>70% recursos:</strong> Motor Themes (lideran√ßa)</li>
                <li><strong>20% recursos:</strong> Basic Themes (diferencia√ß√£o)</li>
                <li><strong>10% recursos:</strong> Emerging Themes (apostas futuras)</li>
            </ul>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.warning("‚ö†Ô∏è Dados insuficientes para mapa tem√°tico")
    
    # ===============================
    # 4. TREND TOPICS
    # ===============================
    elif "4. Trend Topics" in analysis_option:
        st.markdown('<div class="section-header">üìà 4. An√°lise de Tend√™ncias (Trend Topics)</div>', unsafe_allow_html=True)
        
        st.markdown("""
        <div class="explanation-box">
        <h4>üéØ Por que usar Trend Topics?</h4>
        <ul>
            <li><strong>Frequ√™ncia temporal:</strong> Revela picos de interesse (ex: "grafeno em tintas")</li>
            <li><strong>Novos termos:</strong> Identifica rec√©m-chegados ("produ√ß√£o em escala industrial")</li>
            <li><strong>Maturidade tecnol√≥gica:</strong> Compreende ciclo de hype</li>
            <li><strong>Timing de pesquisa:</strong> Orienta quando entrar em novos t√≥picos</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)
        
        # An√°lise de trending topics
        if len(keywords_df) > 0:
            # Top keywords por ano
            yearly_keywords = keywords_df.groupby(['Year', 'Keyword']).size().reset_index(name='Count')
            
            # Selecionar top keywords
            top_kw = keywords_df['Keyword'].value_counts().head(15).index
            trend_data = yearly_keywords[yearly_keywords['Keyword'].isin(top_kw)]
            
            # Heatmap de tend√™ncias
            if len(trend_data) > 0:
                pivot_trend = trend_data.pivot(index='Keyword', columns='Year', values='Count').fillna(0)
                
                fig_trend = px.imshow(pivot_trend, 
                                    title="Heatmap de Tend√™ncias - Top 15 Keywords",
                                    color_continuous_scale='RdYlBu_r')
                st.plotly_chart(fig_trend, use_container_width=True)
            
            # Linha temporal para keywords selecionadas
            st.subheader("üìä Evolu√ß√£o Temporal de Keywords Espec√≠ficas")
            
            selected_keywords = st.multiselect(
                "Selecione at√© 5 keywords para an√°lise temporal:",
                options=list(top_kw),
                default=list(top_kw[:3])
            )
            
            if selected_keywords:
                filter_data = trend_data[trend_data['Keyword'].isin(selected_keywords)]
                fig_lines = px.line(filter_data, x='Year', y='Count', color='Keyword',
                                  title="Evolu√ß√£o Temporal das Keywords Selecionadas",
                                  markers=True)
                st.plotly_chart(fig_lines, use_container_width=True)
            
            # Detec√ß√£o de keywords emergentes
            st.subheader("üöÄ Detec√ß√£o de Keywords Emergentes")
            
            # Keywords que apareceram recentemente (√∫ltimos 3 anos)
            recent_years = df['Year'].max() - 2
            recent_keywords = keywords_df[keywords_df['Year'] >= recent_years]['Keyword'].value_counts()
            all_time_keywords = keywords_df['Keyword'].value_counts()
            
            # Calcular ratio de frequ√™ncia recente vs total
            emerging_score = {}
            for kw in recent_keywords.index:
                if all_time_keywords[kw] >= 3:  # M√≠nimo de ocorr√™ncias
                    ratio = recent_keywords[kw] / all_time_keywords[kw]
                    emerging_score[kw] = ratio
            
            # Top emerging keywords
            if emerging_score:
                emerging_df = pd.DataFrame(list(emerging_score.items()), 
                                         columns=['Keyword', 'Emerging_Score'])
                emerging_df = emerging_df.sort_values('Emerging_Score', ascending=False).head(10)
                
                fig_emerging = px.bar(emerging_df, x='Emerging_Score', y='Keyword', 
                                    orientation='h',
                                    title="Top 10 Keywords Emergentes (Ratio Recente/Total)")
                st.plotly_chart(fig_emerging, use_container_width=True)
            
            # Explica√ß√£o dos trends
            st.markdown("""
            <div class="explanation-box">
            <h4>üîç Como Interpretar Trend Topics:</h4>
            
            <p><strong>üìà Heatmap de Tend√™ncias:</strong></p>
            <ul>
                <li><strong>Cores quentes (vermelho/amarelo):</strong> Per√≠odos de alta atividade</li>
                <li><strong>Cores frias (azul):</strong> Baixa atividade ou temas dormentes</li>
                <li><strong>Padr√µes horizontais:</strong> Temas consistentes ao longo do tempo</li>
                <li><strong>Padr√µes verticais:</strong> Anos de alta atividade geral</li>
            </ul>
            
            <p><strong>üìä Evolu√ß√£o Temporal:</strong></p>
            <ul>
                <li><strong>Curvas ascendentes:</strong> Temas ganhando momentum</li>
                <li><strong>Picos isolados:</strong> Podem indicar eventos espec√≠ficos (regulamenta√ß√µes)</li>
                <li><strong>Decl√≠nios graduais:</strong> Satura√ß√£o ou mudan√ßa tecnol√≥gica</li>
                <li><strong>Ressurg√™ncias:</strong> Temas "voltando √† moda" com novas abordagens</li>
            </ul>
            
            <p><strong>üöÄ Keywords Emergentes (Emerging Score):</strong></p>
            <ul>
                <li><strong>Score > 0.7:</strong> Altamente emergente - investimento priorit√°rio</li>
                <li><strong>Score 0.4-0.7:</strong> Crescimento moderado - monitorar</li>
                <li><strong>Score < 0.4:</strong> Est√°vel ou maduro</li>
            </ul>
            
            <p><strong>üí° Para Tintas Sustent√°veis - A√ß√µes por Trend:</strong></p>
            <ul>
                <li><strong>Se "circular economy" est√° emergente:</strong> Desenvolva programas de reciclagem</li>
                <li><strong>Se "VOC-free" est√° crescendo:</strong> Invista em formula√ß√µes √°gua-base</li>
                <li><strong>Se "bio-based polymers" tem pico:</strong> Parcerias com fornecedores naturais</li>
                <li><strong>Se "nanotechnology" declina:</strong> Foque em nano-seguran√ßa e sustentabilidade</li>
            </ul>
            
            <p><strong>üéØ Timing Estrat√©gico:</strong> Entre em temas emergentes 1-2 anos antes do pico para maximizar vantagem competitiva.</p>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.warning("‚ö†Ô∏è Dados insuficientes para an√°lise de trends")
    
    # ===============================
    # 5. CO-OCORR√äNCIA DE KEYWORDS
    # ===============================
    elif "5. Co-ocorr√™ncia de Keywords" in analysis_option:
        st.markdown('<div class="section-header">üîó 5. An√°lise de Co-ocorr√™ncia de Keywords</div>', unsafe_allow_html=True)
        
        st.markdown("""
        <div class="explanation-box">
        <h4>üéØ Por que usar Co-ocorr√™ncia?</h4>
        <ul>
            <li><strong>Relacionamentos:</strong> Desvela conex√µes entre conceitos</li>
            <li><strong>Exemplo:</strong> "auto-repara√ß√£o" vs "libera√ß√£o controlada"</li>
            <li><strong>Clusters tem√°ticos:</strong> Mapeia grupos de temas relacionados</li>
            <li><strong>Parcerias:</strong> Orienta revis√µes e colabora√ß√µes multidisciplinares</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)
        
        if len(cooccurrence_df) > 0:
            # Calcular matriz de co-ocorr√™ncia
            cooc_counts = cooccurrence_df.groupby(['Keyword1', 'Keyword2']).size().reset_index(name='Count')
            
            # Filtrar por frequ√™ncia m√≠nima
            min_cooc = st.slider("Frequ√™ncia m√≠nima de co-ocorr√™ncia:", 1, 10, 3)
            cooc_filtered = cooc_counts[cooc_counts['Count'] >= min_cooc]
            
            if len(cooc_filtered) > 0:
                # Criar rede de co-ocorr√™ncia
                G = nx.Graph()
                for _, row in cooc_filtered.iterrows():
                    G.add_edge(row['Keyword1'], row['Keyword2'], weight=row['Count'])
                
                st.write(f"üîó Rede de co-ocorr√™ncia: {G.number_of_nodes()} keywords, {G.number_of_edges()} conex√µes")
                
                # Calcular m√©tricas de rede
                if G.number_of_nodes() > 0:
                    centrality = nx.degree_centrality(G)
                    betweenness = nx.betweenness_centrality(G)
                    
                    # Top keywords por centralidade
                    central_df = pd.DataFrame([
                        {'Keyword': k, 'Degree_Centrality': v, 'Betweenness': betweenness[k]}
                        for k, v in centrality.items()
                    ]).sort_values('Degree_Centrality', ascending=False)
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.subheader("üéØ Top Keywords por Centralidade")
                        if len(central_df) > 0:
                            fig_central = px.bar(central_df.head(10), x='Degree_Centrality', y='Keyword',
                                               orientation='h', title="Degree Centrality")
                            st.plotly_chart(fig_central, use_container_width=True)
                    
                    with col2:
                        st.subheader("üåâ Top Keywords por Betweenness")
                        if len(central_df) > 0:
                            fig_between = px.bar(central_df.head(10), x='Betweenness', y='Keyword',
                                               orientation='h', title="Betweenness Centrality")
                            st.plotly_chart(fig_between, use_container_width=True)
                
                # Matriz de co-ocorr√™ncia (heatmap)
                st.subheader("üî• Matriz de Co-ocorr√™ncia")
                
                # Criar matriz pivot
                if len(keywords_df) > 0:
                    top_keywords = keywords_df['Keyword'].value_counts().head(20).index
                    matrix_data = []
                    
                    for kw1 in top_keywords:
                        row = []
                        for kw2 in top_keywords:
                            if kw1 == kw2:
                                row.append(0)
                            else:
                                cooc = cooccurrence_df[
                                    ((cooccurrence_df['Keyword1'] == kw1) & (cooccurrence_df['Keyword2'] == kw2)) |
                                    ((cooccurrence_df['Keyword1'] == kw2) & (cooccurrence_df['Keyword2'] == kw1))
                                ]
                                row.append(len(cooc))
                        matrix_data.append(row)
                    
                    if matrix_data:
                        fig_matrix = px.imshow(matrix_data, 
                                             x=top_keywords, y=top_keywords,
                                             title="Matriz de Co-ocorr√™ncia (Top 20 Keywords)",
                                             color_continuous_scale='Blues')
                        st.plotly_chart(fig_matrix, use_container_width=True)
                
                # Top pares de co-ocorr√™ncia
                st.subheader("üîó Top Pares de Co-ocorr√™ncia")
                top_pairs = cooc_counts.nlargest(15, 'Count')
                top_pairs['Pair'] = top_pairs['Keyword1'] + ' ‚Üî ' + top_pairs['Keyword2']
                
                fig_pairs = px.bar(top_pairs, x='Count', y='Pair', orientation='h',
                                 title="Top 15 Pares Mais Co-ocorrentes")
                st.plotly_chart(fig_pairs, use_container_width=True)
                
                # Explica√ß√£o da co-ocorr√™ncia
                st.markdown("""
                <div class="explanation-box">
                <h4>üîç Como Interpretar Co-ocorr√™ncia de Keywords:</h4>
                
                <p><strong>üéØ Degree Centrality (Centralidade de Grau):</strong></p>
                <ul>
                    <li><strong>Alta centralidade:</strong> Keywords que aparecem com muitas outras</li>
                    <li><strong>Significado:</strong> Conceitos "hub" que conectam diferentes √°reas</li>
                    <li><strong>Estrat√©gia:</strong> Use para integrar diferentes especialidades</li>
                    <li><strong>Exemplo:</strong> "sustainability" pode conectar qu√≠mica, economia e regulamenta√ß√£o</li>
                </ul>
                
                <p><strong>üåâ Betweenness Centrality:</strong></p>
                <ul>
                    <li><strong>Alta betweenness:</strong> Keywords que fazem "ponte" entre clusters</li>
                    <li><strong>Significado:</strong> Conceitos que conectam √°reas distintas</li>
                    <li><strong>Oportunidade:</strong> Temas interdisciplinares para inova√ß√£o</li>
                    <li><strong>Exemplo:</strong> "nanotechnology" pode conectar materiais e aplica√ß√µes</li>
                </ul>
                
                <p><strong>üî• Matriz de Co-ocorr√™ncia:</strong></p>
                <ul>
                    <li><strong>Cores intensas:</strong> Combina√ß√µes frequentes de conceitos</li>
                    <li><strong>Padr√µes de blocos:</strong> Clusters tem√°ticos bem definidos</li>
                    <li><strong>C√©lulas isoladas:</strong> Conex√µes √∫nicas ou raras</li>
                </ul>
                
                <p><strong>üîó Top Pares Co-ocorrentes:</strong></p>
                <ul>
                    <li><strong>Pares com >10 ocorr√™ncias:</strong> Combina√ß√µes consolidadas</li>
                    <li><strong>Pares crescentes:</strong> Novas associa√ß√µes emergindo</li>
                    <li><strong>Aus√™ncias not√°veis:</strong> Oportunidades de conex√£o</li>
                </ul>
                
                <p><strong>üí° Aplica√ß√µes Pr√°ticas:</strong></p>
                <ul>
                    <li><strong>Desenvolvimento de produtos:</strong> Combine conceitos co-ocorrentes</li>
                    <li><strong>Marketing t√©cnico:</strong> Use pares estabelecidos em comunica√ß√£o</li>
                    <li><strong>Parcerias:</strong> Conecte especialistas de conceitos relacionados</li>
                    <li><strong>Literatura review:</strong> Explore conex√µes pouco estudadas</li>
                </ul>
                
                <p><strong>üéØ Exemplo para Tintas:</strong> Se "self-healing" co-ocorre com "microcapsules", 
                desenvolva tintas auto-repar√°veis usando encapsulamento de agentes reparadores.</p>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.warning(f"‚ö†Ô∏è Nenhuma co-ocorr√™ncia encontrada com frequ√™ncia ‚â• {min_cooc}")
        else:
            st.warning("‚ö†Ô∏è Dados insuficientes para an√°lise de co-ocorr√™ncia")
    
    # ===============================
    # 6. REDES DE COLABORA√á√ÉO
    # ===============================
    elif "6. Redes de Colabora√ß√£o" in analysis_option:
        st.markdown('<div class="section-header">ü§ù 6. An√°lise de Redes de Colabora√ß√£o</div>', unsafe_allow_html=True)
        
        st.markdown("""
        <div class="explanation-box">
        <h4>üéØ Por que usar Redes de Colabora√ß√£o?</h4>
        <ul>
            <li><strong>Padr√µes colaborativos:</strong> Revela conex√µes entre pesquisadores</li>
            <li><strong>Hubs de expertise:</strong> Identifica centros de conhecimento</li>
            <li><strong>Transfer√™ncia tecnol√≥gica:</strong> Acelera dissemina√ß√£o de inova√ß√µes</li>
            <li><strong>Oportunidades:</strong> Facilita identifica√ß√£o de novos parceiros</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)
        
        # Rede de colabora√ß√£o entre autores
        collab_network = create_collaboration_network(df)
        
        if collab_network.number_of_nodes() > 0:
            st.write(f"üë• Rede de colabora√ß√£o: {collab_network.number_of_nodes()} autores, {collab_network.number_of_edges()} colabora√ß√µes")
            
            # M√©tricas de rede
            col1, col2, col3 = st.columns(3)
            
            with col1:
                density = nx.density(collab_network)
                st.metric("Densidade da Rede", f"{density:.3f}")
            
            with col2:
                components = nx.number_connected_components(collab_network)
                st.metric("Componentes Conectados", components)
            
            with col3:
                if collab_network.number_of_nodes() > 1:
                    avg_clustering = nx.average_clustering(collab_network)
                    st.metric("Clustering M√©dio", f"{avg_clustering:.3f}")
            
            # Top autores por centralidade
            centrality_measures = {
                'Degree': nx.degree_centrality(collab_network),
                'Betweenness': nx.betweenness_centrality(collab_network),
                'Closeness': nx.closeness_centrality(collab_network)
            }
            
            measure_choice = st.selectbox("Selecione medida de centralidade:", 
                                        ['Degree', 'Betweenness', 'Closeness'])
            
            selected_centrality = centrality_measures[measure_choice]
            central_authors = pd.DataFrame([
                {'Author': author, 'Centrality': centrality}
                for author, centrality in selected_centrality.items()
            ]).sort_values('Centrality', ascending=False).head(15)
            
            fig_central_authors = px.bar(central_authors, x='Centrality', y='Author', 
                                       orientation='h',
                                       title=f"Top 15 Autores por {measure_choice} Centrality")
            st.plotly_chart(fig_central_authors, use_container_width=True)
            
            # An√°lise de pa√≠ses (se dispon√≠vel)
            if 'Affiliations' in df.columns:
                st.subheader("üåç Colabora√ß√£o por Pa√≠ses")
                
                # Extrair pa√≠ses das afilia√ß√µes
                countries = []
                for affiliation in df['Affiliations'].dropna():
                    # Busca padr√µes simples de pa√≠ses
                    common_countries = ['USA', 'China', 'Germany', 'Japan', 'UK', 'France', 'Italy', 
                                      'Canada', 'Australia', 'South Korea', 'Netherlands', 'Sweden']
                    for country in common_countries:
                        if country.lower() in str(affiliation).lower():
                            countries.append(country)
                            break
                
                if countries:
                    country_counts = pd.Series(countries).value_counts()
                    
                    fig_countries = px.bar(x=country_counts.values, y=country_counts.index,
                                         orientation='h', title="Produ√ß√£o por Pa√≠s")
                    st.plotly_chart(fig_countries, use_container_width=True)
                    
            # Explica√ß√£o das redes de colabora√ß√£o
            st.markdown("""
            <div class="explanation-box">
            <h4>üîç Como Interpretar Redes de Colabora√ß√£o:</h4>
            
            <p><strong>üìä M√©tricas da Rede:</strong></p>
            <ul>
                <li><strong>Densidade (0-1):</strong> >0.1 = rede bem conectada, <0.05 = fragmentada</li>
                <li><strong>Componentes conectados:</strong> Menor n√∫mero = melhor integra√ß√£o</li>
                <li><strong>Clustering m√©dio:</strong> >0.3 = tend√™ncia a formar grupos colaborativos</li>
            </ul>
            
            <p><strong>üéØ Degree Centrality (Colabora√ß√µes Diretas):</strong></p>
            <ul>
                <li><strong>Top autores:</strong> Hubs de colabora√ß√£o - potenciais mentores</li>
                <li><strong>Estrat√©gia:</strong> Conecte-se com estes para ampliar rede</li>
                <li><strong>Indicador:</strong> Experi√™ncia em lideran√ßa de projetos</li>
            </ul>
            
            <p><strong>üåâ Betweenness Centrality (Conectores):</strong></p>
            <ul>
                <li><strong>Papel:</strong> Autores que conectam grupos diferentes</li>
                <li><strong>Valor:</strong> Facilitam transfer√™ncia de conhecimento entre √°reas</li>
                <li><strong>Oportunidade:</strong> Ideais para projetos interdisciplinares</li>
            </ul>
            
            <p><strong>üèÉ Closeness Centrality (Proximidade):</strong></p>
            <ul>
                <li><strong>Interpreta√ß√£o:</strong> Rapidez para acessar toda a rede</li>
                <li><strong>Vantagem:</strong> Acesso r√°pido a informa√ß√µes e recursos</li>
                <li><strong>Estrat√©gia:</strong> Bons para dissemina√ß√£o de inova√ß√µes</li>
            </ul>
            
            <p><strong>üåç An√°lise por Pa√≠ses:</strong></p>
            <ul>
                <li><strong>Pa√≠ses l√≠deres:</strong> Onde buscar parcerias internacionais</li>
                <li><strong>Mercados emergentes:</strong> Oportunidades de pioneirismo</li>
                <li><strong>Regulamenta√ß√µes:</strong> Pa√≠ses com normas avan√ßadas em sustentabilidade</li>
            </ul>
            
            <p><strong>üí° A√ß√µes Estrat√©gicas:</strong></p>
            <ul>
                <li><strong>Parcerias prim√°rias:</strong> Colabore com autores de alta centralidade</li>
                <li><strong>Acesso a redes:</strong> Use conectores para entrar em novos grupos</li>
                <li><strong>Expans√£o geogr√°fica:</strong> Foque nos top 3 pa√≠ses por produ√ß√£o</li>
                <li><strong>Nichos:</strong> Explore pa√≠ses com crescimento acelerado</li>
            </ul>
            
            <p><strong>üéØ Para Tintas Sustent√°veis:</strong> Conecte-se com grupos que combinam 
            expertise em materiais + sustentabilidade + aplica√ß√µes industriais.</p>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.warning("‚ö†Ô∏è Dados insuficientes para an√°lise de colabora√ß√£o")
    
    # ===============================
    # 7. AN√ÅLISE DE CO-CITA√á√ÉO
    # ===============================
    elif "7. An√°lise de Co-cita√ß√£o" in analysis_option:
        st.markdown('<div class="section-header">üìö 7. An√°lise de Co-cita√ß√£o</div>', unsafe_allow_html=True)
        
        st.markdown("""
        <div class="explanation-box">
        <h4>üéØ Por que usar Co-cita√ß√£o?</h4>
        <ul>
            <li><strong>Base te√≥rica:</strong> Identifica refer√™ncias centrais da √°rea</li>
            <li><strong>Estrutura metodol√≥gica:</strong> Mapeia fundamentos conceituais</li>
            <li><strong>Refer√™ncia robusta:</strong> Auxilia constru√ß√£o de framework te√≥rico</li>
            <li><strong>Evolu√ß√£o do conhecimento:</strong> Mostra como ideias se conectam</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)
        
        # Simula√ß√£o de an√°lise de co-cita√ß√£o (dados reais requerem refer√™ncias)
        st.info("üìù **Nota:** An√°lise de co-cita√ß√£o completa requer dados de refer√™ncias dos artigos. Aqui apresentamos uma simula√ß√£o baseada nos artigos mais citados.")
        
        # Usar artigos mais citados como proxy para an√°lise
        top_cited = df.nlargest(20, 'Citations')[['Title', 'Authors', 'Year', 'Citations', 'Journal']]
        
        st.subheader("üìà Top 20 Artigos Mais Citados (Base de Co-cita√ß√£o)")
        
        # Visualiza√ß√£o dos top papers
        fig_top_papers = px.bar(top_cited.sort_values('Citations'), 
                              x='Citations', y='Title',
                              orientation='h',
                              title="Artigos Mais Citados (Candidatos para Co-cita√ß√£o)")
        # CORRIGIDO: usar update_yaxes em vez de update_yaxis
        fig_top_papers.update_yaxes(title="")
        fig_top_papers.update_layout(yaxis={'categoryorder': 'total ascending'})
        st.plotly_chart(fig_top_papers, use_container_width=True)
        
        # An√°lise temporal dos papers fundamentais
        st.subheader("‚è∞ Distribui√ß√£o Temporal dos Papers Fundamentais")
        
        yearly_top = top_cited['Year'].value_counts().sort_index()
        fig_yearly_top = px.bar(x=yearly_top.index, y=yearly_top.values,
                              title="Distribui√ß√£o Anual dos Top Papers")
        fig_yearly_top.update_layout(xaxis_title="Ano", yaxis_title="N√∫mero de Papers")
        st.plotly_chart(fig_yearly_top, use_container_width=True)
        
        # Journals dos papers mais citados
        st.subheader("üìñ Revistas dos Papers Fundamentais")
        
        journal_top = top_cited['Journal'].value_counts()
        fig_journal_top = px.pie(values=journal_top.values, names=journal_top.index,
                                title="Distribui√ß√£o por Revista (Top Papers)")
        st.plotly_chart(fig_journal_top, use_container_width=True)
        
        # Tabela detalhada
        st.subheader("üìã Detalhes dos Papers Fundamentais")
        
        display_df = top_cited.copy()
        display_df['Title'] = display_df['Title'].str[:60] + "..."
        display_df['Authors'] = display_df['Authors'].str[:40] + "..."
        
        st.dataframe(display_df, use_container_width=True)
        
        # Explica√ß√£o da co-cita√ß√£o
        st.markdown("""
        <div class="explanation-box">
        <h4>üîç Como Interpretar An√°lise de Co-cita√ß√£o:</h4>
        
        <p><strong>üìö Papers Fundamentais (Top Citados):</strong></p>
        <ul>
            <li><strong>Base te√≥rica:</strong> Artigos que formam a funda√ß√£o conceitual da √°rea</li>
            <li><strong>Metodologias-chave:</strong> T√©cnicas e abordagens estabelecidas</li>
            <li><strong>Marcos hist√≥ricos:</strong> Breakthrough papers que mudaram o campo</li>
            <li><strong>Refer√™ncias obrigat√≥rias:</strong> Devem estar em qualquer revis√£o de literatura</li>
        </ul>
        
        <p><strong>‚è∞ Distribui√ß√£o Temporal:</strong></p>
        <ul>
            <li><strong>Papers antigos (>10 anos):</strong> Fundamentos te√≥ricos estabelecidos</li>
            <li><strong>Papers recentes (<5 anos):</strong> Dire√ß√µes atuais e emergentes</li>
            <li><strong>Gaps temporais:</strong> Per√≠odos de menor atividade fundacional</li>
            <li><strong>Acelera√ß√£o recente:</strong> Indica √°rea em r√°pido desenvolvimento</li>
        </ul>
        
        <p><strong>üìñ Revistas Centrais:</strong></p>
        <ul>
            <li><strong>Concentra√ß√£o alta:</strong> Poucas revistas dominam os fundamentos</li>
            <li><strong>Diversifica√ß√£o:</strong> √Årea interdisciplinar com m√∫ltiplas fontes</li>
            <li><strong>Revistas especializadas:</strong> Foco t√©cnico espec√≠fico</li>
            <li><strong>Revistas gerais:</strong> Impacto amplo e visibilidade</li>
        </ul>
        
        <p><strong>üí° Como Usar para Co-cita√ß√£o Completa:</strong></p>
        <ul>
            <li><strong>Identifique clusters:</strong> Papers citados juntos formam escolas de pensamento</li>
            <li><strong>Evolu√ß√£o conceitual:</strong> Como ideias fundamentais se desenvolveram</li>
            <li><strong>Lacunas te√≥ricas:</strong> √Åreas com poucos papers fundamentais</li>
            <li><strong>Oportunidades:</strong> Conectar teorias de diferentes clusters</li>
        </ul>
        
        <p><strong>üéØ Estrat√©gias Baseadas nos Resultados:</strong></p>
        <ul>
            <li><strong>Literatura review:</strong> Inclua todos os top 20 papers como base</li>
            <li><strong>Posicionamento:</strong> Compare sua abordagem com os fundamentos</li>
            <li><strong>Inova√ß√£o:</strong> Combine conceitos de papers pouco co-citados</li>
            <li><strong>Credibilidade:</strong> Demonstre conhecimento dos cl√°ssicos</li>
        </ul>
        
        <p><strong>üìù Para Tintas Sustent√°veis:</strong></p>
        <ul>
            <li><strong>Se dom√≠nio √© "coating performance":</strong> Base s√≥lida em funcionalidade</li>
            <li><strong>Se gaps em "sustainability":</strong> Oportunidade para papers fundacionais</li>
            <li><strong>Revistas diversas:</strong> √Årea interdisciplinar - abordagem integrada necess√°ria</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)
    
    # ===============================
    # 8. TOP PAPERS (CITA√á√ïES)
    # ===============================
    elif "8. Top Papers" in analysis_option:
        st.markdown('<div class="section-header">üèÜ 8. An√°lise de Cita√ß√µes Diretas (Top Papers)</div>', unsafe_allow_html=True)
        
        st.markdown("""
        <div class="explanation-box">
        <h4>üéØ Por que usar Top Papers?</h4>
        <ul>
            <li><strong>Maior impacto:</strong> Aponta artigos mais influentes da √°rea</li>
            <li><strong>Relev√¢ncia:</strong> √ötil para justificar import√¢ncia da pesquisa</li>
            <li><strong>Posicionamento:</strong> Permite posicionar contribui√ß√µes pr√≥prias</li>
            <li><strong>Benchmarking:</strong> Define padr√µes de qualidade e impacto</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)
        
        # An√°lise detalhada de cita√ß√µes
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Total de Cita√ß√µes", f"{df['Citations'].sum():,}")
        with col2:
            st.metric("M√©dia de Cita√ß√µes", f"{df['Citations'].mean():.1f}")
        with col3:
            st.metric("√çndice H", f"{h_index}")
        
        # Distribui√ß√£o de cita√ß√µes
        st.subheader("üìä Distribui√ß√£o de Cita√ß√µes")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # CORRIGIDO: usar nbins em vez de bins
            fig_hist = px.histogram(df, x='Citations', nbins=30, 
                                  title="Histograma de Cita√ß√µes")
            fig_hist.add_vline(x=df['Citations'].mean(), line_dash="dash", 
                             annotation_text=f"M√©dia: {df['Citations'].mean():.1f}")
            st.plotly_chart(fig_hist, use_container_width=True)
        
        with col2:
            fig_box = px.box(df, y='Citations', title="Box Plot de Cita√ß√µes")
            st.plotly_chart(fig_box, use_container_width=True)
        
        # Top papers detalhado
        st.subheader("ü•á Top 20 Papers Mais Citados")
        
        top_papers = df.nlargest(20, 'Citations')[['Title', 'Authors', 'Year', 'Citations', 'Journal']]
        
        # Gr√°fico de barras
        fig_top = px.bar(top_papers.sort_values('Citations'), x='Citations', y='Title',
                        orientation='h', color='Year',
                        title="Top 20 Papers por Cita√ß√µes")
        # CORRIGIDO: usar update_yaxes
        fig_top.update_yaxes(categoryorder='total ascending')
        st.plotly_chart(fig_top, use_container_width=True)
        
        # An√°lise de Pareto
        st.subheader("üìà An√°lise de Pareto (80/20)")
        
        sorted_citations = df['Citations'].sort_values(ascending=False)
        cumsum_citations = sorted_citations.cumsum()
        total_citations = cumsum_citations.iloc[-1]
        
        pareto_df = pd.DataFrame({
            'Paper_Rank': range(1, len(sorted_citations) + 1),
            'Cumulative_Percentage': (cumsum_citations / total_citations) * 100,
            'Citations': sorted_citations.values
        })
        
        # Encontrar ponto de 80%
        pareto_80_idx = pareto_df[pareto_df['Cumulative_Percentage'] >= 80].index[0]
        papers_80 = pareto_80_idx + 1
        
        fig_pareto = px.line(pareto_df, x='Paper_Rank', y='Cumulative_Percentage',
                           title=f"Curva de Pareto - {papers_80} papers (80% das cita√ß√µes)")
        fig_pareto.add_hline(y=80, line_dash="dash", annotation_text="80%")
        fig_pareto.add_vline(x=papers_80, line_dash="dash", 
                           annotation_text=f"{papers_80} papers")
        st.plotly_chart(fig_pareto, use_container_width=True)
        
        st.info(f"üìä **Insight Pareto:** {papers_80} papers ({papers_80/len(df)*100:.1f}% do total) concentram 80% de todas as cita√ß√µes")
        
        # Tabela interativa dos top papers
        st.subheader("üìã Tabela Detalhada dos Top Papers")
        
        display_top = top_papers.copy()
        display_top.index = range(1, len(display_top) + 1)
        st.dataframe(display_top, use_container_width=True)
        
        # Explica√ß√£o da an√°lise de cita√ß√µes
        st.markdown(f"""
        <div class="explanation-box">
        <h4>üîç Como Interpretar An√°lise de Top Papers:</h4>
        
        <p><strong>üìä M√©tricas de Impacto:</strong></p>
        <ul>
            <li><strong>Total de cita√ß√µes:</strong> Impacto cumulativo da √°rea</li>
            <li><strong>M√©dia de cita√ß√µes:</strong> Benchmark para avaliar qualidade</li>
            <li><strong>√çndice H:</strong> Equilibrio entre produtividade e impacto</li>
        </ul>
        
        <p><strong>üìà Distribui√ß√£o de Cita√ß√µes:</strong></p>
        <ul>
            <li><strong>Histograma assim√©trico:</strong> Normal - poucos papers muito citados</li>
            <li><strong>Cauda longa:</strong> Maioria dos papers tem poucas cita√ß√µes</li>
            <li><strong>Outliers:</strong> Papers breakthrough com impacto excepcional</li>
            <li><strong>Box plot:</strong> Mostra quartis e identifica papers at√≠picos</li>
        </ul>
        
        <p><strong>üèÜ Top Papers (Ranking):</strong></p>
        <ul>
            <li><strong>Top 1-5:</strong> Cl√°ssicos absolutos - estudar profundamente</li>
            <li><strong>Top 6-15:</strong> Referencias importantes - conhecer bem</li>
            <li><strong>Top 16-50:</strong> Papers relevantes - familiarizar-se</li>
            <li><strong>Tend√™ncia por cor/ano:</strong> Papers recentes subindo rapidamente</li>
        </ul>
        
        <p><strong>üìà Princ√≠pio de Pareto (80/20):</strong></p>
        <ul>
            <li><strong>Concentra√ß√£o de impacto:</strong> Poucos papers dominam cita√ß√µes</li>
            <li><strong>Significado:</strong> Qualidade > Quantidade na pesquisa</li>
            <li><strong>Estrat√©gia:</strong> Foque em produzir papers de alto impacto</li>
            <li><strong>Benchmark:</strong> Entre no grupo dos 20% mais citados</li>
        </ul>
        
        <p><strong>üí° An√°lise de Perfil dos Top Papers:</strong></p>
        <ul>
            <li><strong>Anos mais citados:</strong> Identifica per√≠odos de breakthrough</li>
            <li><strong>Revistas dominantes:</strong> Onde publicar para maior impacto</li>
            <li><strong>Tipos de paper:</strong> Reviews vs. artigos originais vs. m√©todos</li>
            <li><strong>Temas recorrentes:</strong> Assuntos que geram alto impacto</li>
        </ul>
        
        <p><strong>üéØ Estrat√©gias Baseadas nos Resultados:</strong></p>
        <ul>
            <li><strong>Benchmarking:</strong> Compare seu trabalho com os top papers</li>
            <li><strong>Gaps de cita√ß√£o:</strong> Identifique temas pouco explorados nos tops</li>
            <li><strong>Colabora√ß√£o:</strong> Conecte-se com autores dos papers mais citados</li>
            <li><strong>Posicionamento:</strong> Cite e construa sobre os fundamentos estabelecidos</li>
        </ul>
        
        <p><strong>üìù Para Tintas Sustent√°veis - A√ß√µes:</strong></p>
        <ul>
            <li><strong>Se top papers s√£o sobre "performance":</strong> Inova√ß√£o sustent√°vel deve manter qualidade</li>
            <li><strong>Se poucos sobre "sustainability":</strong> Oportunidade de papers de alto impacto</li>
            <li><strong>Reviews bem citadas:</strong> Considere escrever review abrangente</li>
            <li><strong>M√©todos novos:</strong> Desenvolva t√©cnicas inovadoras de caracteriza√ß√£o</li>
        </ul>
        
        <p><strong>üéØ Meta de Impacto:</strong> Almeje estar entre os top 20% mais citados da √°rea 
        (acima de {df['Citations'].quantile(0.8):.0f} cita√ß√µes com base nos dados atuais).</p>
        </div>
        """, unsafe_allow_html=True)
    
    # ===============================
    # 9. LEI DE LOTKA
    # ===============================
    elif "9. Lei de Lotka" in analysis_option:
        st.markdown('<div class="section-header">üìê 9. An√°lise de Autores & Lei de Lotka</div>', unsafe_allow_html=True)
        
        st.markdown("""
        <div class="explanation-box">
        <h4>üéØ Por que usar Lei de Lotka?</h4>
        <ul>
            <li><strong>Pesquisadores-chave:</strong> Identifica autores mais produtivos</li>
            <li><strong>Padr√µes de produtividade:</strong> Revela distribui√ß√£o estat√≠stica</li>
            <li><strong>Redes de influ√™ncia:</strong> Mapeia hierarquias acad√™micas</li>
            <li><strong>Coautores potenciais:</strong> Facilita identifica√ß√£o de parceiros</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)
        
        # Processar dados de autores
        all_authors = []
        for authors_str in df['Authors'].dropna():
            authors = [a.strip() for a in str(authors_str).split(';')]
            all_authors.extend(authors)
        
        author_productivity = pd.Series(all_authors).value_counts()
        author_stats_df = pd.DataFrame({
            'Author': author_productivity.index,
            'Papers_Count': author_productivity.values
        })
        
        # Calcular cita√ß√µes por autor
        author_citations = {}
        for _, row in df.iterrows():
            if pd.notna(row['Authors']):
                authors = [a.strip() for a in str(row['Authors']).split(';')]
                for author in authors:
                    if author in author_citations:
                        author_citations[author] += row['Citations']
                    else:
                        author_citations[author] = row['Citations']
        
        author_stats_df['Total_Citations'] = author_stats_df['Author'].map(author_citations).fillna(0)
        author_stats_df['Avg_Citations'] = (author_stats_df['Total_Citations'] / 
                                          author_stats_df['Papers_Count']).round(2)
        
        # M√©tricas gerais
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Autores √önicos", len(author_stats_df))
        with col2:
            st.metric("Autor Mais Produtivo", f"{author_stats_df.iloc[0]['Papers_Count']} papers")
        with col3:
            avg_papers = author_stats_df['Papers_Count'].mean()
            st.metric("M√©dia Papers/Autor", f"{avg_papers:.1f}")
        
        # Top autores
        st.subheader("üèÜ Top 20 Autores Mais Produtivos")
        
        top_authors = author_stats_df.head(20)
        
        fig_authors = px.bar(top_authors, x='Papers_Count', y='Author', 
                           orientation='h', color='Total_Citations',
                           title="Produtividade dos Autores")
        # CORRIGIDO: usar update_yaxes
        fig_authors.update_yaxes(categoryorder='total ascending')
        st.plotly_chart(fig_authors, use_container_width=True)
        
        # An√°lise da Lei de Lotka
        st.subheader("üìê An√°lise da Lei de Lotka")
        
        productivity_counts, frequencies, alpha = analyze_lotka_law(author_stats_df)
        
        if alpha is not None:
            # Gr√°fico log-log da Lei de Lotka
            fig_lotka = px.scatter(x=productivity_counts, y=frequencies,
                                 title=f"Lei de Lotka (Œ± = {alpha:.2f})",
                                 log_x=True, log_y=True)
            fig_lotka.update_layout(
                xaxis_title="N√∫mero de Papers (log)",
                yaxis_title="N√∫mero de Autores (log)"
            )
            
            # Adicionar linha te√≥rica
            x_theory = np.logspace(0, np.log10(max(productivity_counts)), 100)
            y_theory = frequencies[0] * (x_theory[0] / x_theory) ** alpha
            
            fig_lotka.add_scatter(x=x_theory, y=y_theory, mode='lines',
                                name=f'Lei de Lotka (Œ±={alpha:.2f})',
                                line=dict(dash='dash'))
            
            st.plotly_chart(fig_lotka, use_container_width=True)
            
            # Interpreta√ß√£o
            st.markdown(f"""
            <div class="metric-card">
            <h4>üîç Interpreta√ß√£o da Lei de Lotka</h4>
            <p><strong>Expoente Œ± = {alpha:.2f}</strong></p>
            <ul>
                <li>Œ± ‚âà 2: Distribui√ß√£o cl√°ssica de Lotka (poucos autores muito produtivos)</li>
                <li>Œ± > 2: Concentra√ß√£o ainda maior nos top autores</li>
                <li>Œ± < 2: Distribui√ß√£o mais igualit√°ria</li>
            </ul>
            <p><strong>Seu resultado ({alpha:.2f}):</strong> {'Concentra√ß√£o alta' if alpha > 2 else 'Concentra√ß√£o moderada' if alpha > 1.5 else 'Distribui√ß√£o equilibrada'}</p>
            </div>
            """, unsafe_allow_html=True)
        
        # Distribui√ß√£o de produtividade
        st.subheader("üìä Distribui√ß√£o de Produtividade")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # CORRIGIDO: usar nbins
            fig_dist = px.histogram(author_stats_df, x='Papers_Count', nbins=20,
                                  title="Distribui√ß√£o de Papers por Autor")
            st.plotly_chart(fig_dist, use_container_width=True)
        
        with col2:
            # Estat√≠sticas de produtividade
            prod_stats = author_stats_df['Papers_Count'].describe()
            
            st.markdown("""
            **üìà Estat√≠sticas de Produtividade:**
            """)
            for stat, value in prod_stats.items():
                st.write(f"- **{stat.title()}:** {value:.1f}")
        
        # Tabela dos top autores
        st.subheader("üìã Detalhes dos Top Autores")
        
        display_authors = top_authors.copy()
        display_authors.index = range(1, len(display_authors) + 1)
        display_authors['Author'] = display_authors['Author'].str[:40] + "..."
        
        st.dataframe(display_authors, use_container_width=True)
        
        # Explica√ß√£o da Lei de Lotka
        st.markdown(f"""
        <div class="explanation-box">
        <h4>üîç Como Interpretar Lei de Lotka & An√°lise de Autores:</h4>
        
        <p><strong>üìê Lei de Lotka (Œ± = {alpha if alpha else 'N/A':.2f}):</strong></p>
        <ul>
            <li><strong>Œ± ‚âà 2.0:</strong> Distribui√ß√£o cl√°ssica - poucos autores muito produtivos</li>
            <li><strong>Œ± > 2.0:</strong> Concentra√ß√£o ainda maior nos top autores</li>
            <li><strong>Œ± < 2.0:</strong> Distribui√ß√£o mais equilibrada entre autores</li>
            <li><strong>Seu resultado ({alpha if alpha else 'N/A':.2f}):</strong> {'Concentra√ß√£o alta nos top autores' if alpha and alpha > 2 else 'Concentra√ß√£o moderada' if alpha and alpha > 1.5 else 'Distribui√ß√£o mais equilibrada'}</li>
        </ul>
        
        <p><strong>üèÜ Hierarquia de Produtividade:</strong></p>
        <ul>
            <li><strong>Top 1-5 autores:</strong> Elite cient√≠fica - l√≠deres estabelecidos</li>
            <li><strong>Top 6-20:</strong> Pesquisadores senior - potenciais mentores</li>
            <li><strong>Cauda longa:</strong> Maioria publica poucos papers - oportunidade</li>
        </ul>
        
        <p><strong>üìä M√©tricas de Autor:</strong></p>
        <ul>
            <li><strong>Papers por autor:</strong> Produtividade bruta</li>
            <li><strong>Cita√ß√µes totais:</strong> Impacto cumulativo</li>
            <li><strong>Cita√ß√µes m√©dias:</strong> Qualidade por paper</li>
            <li><strong>Combina√ß√£o ideal:</strong> Alta produtividade + Alto impacto</li>
        </ul>
        
        <p><strong>üìà Distribui√ß√£o de Produtividade:</strong></p>
        <ul>
            <li><strong>Moda baixa:</strong> Maioria dos autores publica pouco</li>
            <li><strong>Outliers:</strong> Autores excepcionalmente produtivos</li>
            <li><strong>Mediana vs M√©dia:</strong> Assimetria indica concentra√ß√£o</li>
        </ul>
        
        <p><strong>üí° Estrat√©gias por N√≠vel de Autor:</strong></p>
        
        <p><strong>üéØ Para Pesquisadores Iniciantes:</strong></p>
        <ul>
            <li><strong>Objetivo:</strong> Entrar no top 50% (>{author_stats_df['Papers_Count'].quantile(0.5):.1f} papers)</li>
            <li><strong>Estrat√©gia:</strong> Colabore com autores produtivos</li>
            <li><strong>Foco:</strong> Qualidade > Quantidade inicialmente</li>
        </ul>
        
        <p><strong>üéØ Para Pesquisadores Intermedi√°rios:</strong></p>
        <ul>
            <li><strong>Objetivo:</strong> Top 20 autores da √°rea</li>
            <li><strong>Estrat√©gia:</strong> Lidere projetos colaborativos</li>
            <li><strong>Foco:</strong> Estabele√ßa programa de pesquisa consistente</li>
        </ul>
        
        <p><strong>üéØ Para L√≠deres Estabelecidos:</strong></p>
        <ul>
            <li><strong>Objetivo:</strong> Manter posi√ß√£o top 5</li>
            <li><strong>Estrat√©gia:</strong> Mentorar novos pesquisadores</li>
            <li><strong>Foco:</strong> Papers de alto impacto e reviews influentes</li>
        </ul>
        
        <p><strong>ü§ù Identifica√ß√£o de Parceiros:</strong></p>
        <ul>
            <li><strong>Alta produtividade + Baixo impacto:</strong> Precisam melhorar qualidade</li>
            <li><strong>Baixa produtividade + Alto impacto:</strong> Foco em qualidade</li>
            <li><strong>Crescimento r√°pido:</strong> Estrelas em ascens√£o</li>
            <li><strong>Veteranos est√°veis:</strong> Experi√™ncia e redes estabelecidas</li>
        </ul>
        
        <p><strong>üìù Para Tintas Sustent√°veis - A√ß√µes:</strong></p>
        <ul>
            <li><strong>Conecte-se com top 10:</strong> Para projetos de alto impacto</li>
            <li><strong>Monitore emergentes:</strong> Colabora√ß√µes futuras promissoras</li>
            <li><strong>Diversidade geogr√°fica:</strong> Amplie rede internacional</li>
            <li><strong>Especializa√ß√£o complementar:</strong> Combine expertise qu√≠mica + aplicada</li>
        </ul>
        
        <p><strong>üéØ Meta Pessoal:</strong> Para entrar no top 20% da √°rea, almeje >{author_stats_df['Papers_Count'].quantile(0.8)} papers 
        com impacto m√©dio de >{author_stats_df['Avg_Citations'].quantile(0.8):.1f} cita√ß√µes por paper.</p>
        </div>
        """, unsafe_allow_html=True)
    
    # ===============================
    # RESUMO EXECUTIVO
    # ===============================
    
    # Se√ß√£o de Insights Gerais
    st.markdown('<div class="section-header">üí° Resumo Executivo & Insights Estrat√©gicos</div>', unsafe_allow_html=True)
    
    with st.expander("üìä Resumo Executivo - Todas as An√°lises", expanded=True):
        st.markdown(f"""
        ### üéØ Principais Descobertas
        
        **üìà Estado da Arte:**
        - **Volume de pesquisa:** {len(df)} artigos analisados
        - **Impacto cient√≠fico:** {df['Citations'].sum()} cita√ß√µes totais (H-index: {h_index})
        - **Per√≠odo coberto:** {df['Year'].min()}-{df['Year'].max()}
        - **Colabora√ß√£o:** {collaboration_rate*100:.1f}% dos papers s√£o colaborativos
        
        **üå± Evolu√ß√£o Tem√°tica:**
        - **Temas emergentes:** Identifique trends positivos para investimento
        - **√Åreas maduras:** Aproveite conhecimento consolidado
        - **Lacunas temporais:** Oportunidades para pesquisa pioneira
        
        **üó∫Ô∏è Posicionamento Estrat√©gico:**
        - **Motor Themes:** √Åreas para lideran√ßa e diferencia√ß√£o
        - **Basic Themes:** Fundamentos para especializa√ß√£o
        - **Niche Themes:** Mercados rent√°veis espec√≠ficos
        - **Emerging Themes:** Apostas para o futuro
        
        **üîó Redes de Conhecimento:**
        - **Conceitos centrais:** Use para integrar especialidades
        - **Bridges:** Explore conex√µes interdisciplinares
        - **Clusters:** Identifique comunidades de pr√°tica
        
        **ü§ù Ecossistema de Colabora√ß√£o:**
        - **Hubs de expertise:** Conecte-se para ampliar capacidades
        - **Conectores de rede:** Acesse diferentes comunidades
        - **Especialistas por pa√≠s:** Oportunidades globais
        
        ### üéØ Recomenda√ß√µes Estrat√©gicas
        
        **Para P&D (Pesquisa & Desenvolvimento):**
        1. **Investimento Principal (70%):** Foque em Motor Themes identificados
        2. **Diferencia√ß√£o (20%):** Explore Basic Themes pouco desenvolvidos
        3. **Inova√ß√£o Radical (10%):** Aposte em Emerging Themes promissores
        
        **Para Parcerias Acad√™micas:**
        1. **Conecte-se** com autores de alta centralidade
        2. **Colabore** com bridges entre diferentes √°reas
        3. **Monitore** pesquisadores emergentes em crescimento r√°pido
        
        **Para Publica√ß√£o Cient√≠fica:**
        1. **Journals alvo:** Foque nas top 5 revistas da √°rea
        2. **Timing:** Entre em temas emergentes antes do pico
        3. **Impacto:** Almeje top 20% em cita√ß√µes (>{df['Citations'].quantile(0.8):.0f} cita√ß√µes)
        
        **Para Inova√ß√£o Tecnol√≥gica:**
        1. **Combine** conceitos co-ocorrentes frequentemente
        2. **Explore** conex√µes raras entre temas
        3. **Antecipe** tend√™ncias com base na evolu√ß√£o temporal
        """)
    
    with st.expander("üî¨ Insights Espec√≠ficos para Tintas e Revestimentos Sustent√°veis"):
        st.markdown("""
        ### üåø Oportunidades Identificadas
        
        **Materiais Bio-baseados:**
        - **Tend√™ncia:** Crescimento consistente em pol√≠meros naturais
        - **A√ß√£o:** Desenvolva parcerias com fornecedores de biomassa
        - **Timing:** Mercado em expans√£o - entre agora
        
        **Economia Circular:**
        - **Gap identificado:** Poucos estudos sobre reciclabilidade de tintas
        - **Oportunidade:** Lidere desenvolvimento de tintas 100% recicl√°veis
        - **Diferencial:** Combine performance + sustentabilidade
        
        **Funcionalidades Inteligentes:**
        - **Emerg√™ncia:** Auto-repara√ß√£o e propriedades adaptativas
        - **Tecnologia:** Microencapsulamento e nanomateriais seguros
        - **Mercado:** Premium pricing para funcionalidades avan√ßadas
        
        **Regulamenta√ß√£o Ambiental:**
        - **Driving force:** Normas cada vez mais restritivas
        - **Oportunidade:** Antecipe-se √†s regulamenta√ß√µes futuras
        - **Vantagem:** First-mover advantage em compliance
        
        ### üéØ Roadmap Tecnol√≥gico Sugerido
        
        **Curto Prazo (1-2 anos):**
        1. **Formula√ß√µes water-based** com performance equivalent solvent-based
        2. **Redu√ß√£o de VOCs** para <50g/L em todas as categorias
        3. **Parcerias** com universidades top da √°rea
        
        **M√©dio Prazo (3-5 anos):**
        1. **Tintas auto-repar√°veis** para aplica√ß√µes espec√≠ficas
        2. **Conte√∫do reciclado** >30% sem perda de qualidade
        3. **Certifica√ß√µes** ambientais reconhecidas internacionalmente
        
        **Longo Prazo (5+ anos):**
        1. **Economia circular completa** - tintas 100% recicl√°veis
        2. **Smart coatings** com funcionalidades sensoriais
        3. **Lideran√ßa global** em sustentabilidade do setor
        
        ### üí° Indicadores de Sucesso
        
        **M√©tricas de Inova√ß√£o:**
        - **Patentes:** >5 por ano em sustentabilidade
        - **Publica√ß√µes:** Top 20% em impacto cient√≠fico
        - **Parcerias:** >3 universidades de ponta
        
        **M√©tricas de Mercado:**
        - **Market share:** Lideran√ßa em segmento sustent√°vel
        - **Premium pricing:** 10-15% acima da m√©dia
        - **Customer satisfaction:** >95% em performance + sustentabilidade
        
        **M√©tricas Ambientais:**
        - **Carbon footprint:** Redu√ß√£o 50% at√© 2030
        - **Waste reduction:** 80% dos materiais reaproveitados
        - **LCA score:** Melhor da categoria em todas as m√©tricas
        """)
        
    # Footer com call-to-action
    st.markdown("""
    ---
    <div style="text-align: center; padding: 2rem; background-color: #f0f9ff; border-radius: 0.5rem; margin: 2rem 0;">
        <h3>üöÄ Pr√≥ximos Passos</h3>
        <p><strong>Use estas an√°lises para:</strong></p>
        <p>‚úÖ Definir estrat√©gia de P&D ‚Ä¢ ‚úÖ Identificar parceiros ‚Ä¢ ‚úÖ Priorizar investimentos</p>
        <p>‚úÖ Orientar publica√ß√µes ‚Ä¢ ‚úÖ Antecipar tend√™ncias ‚Ä¢ ‚úÖ Liderar inova√ß√£o sustent√°vel</p>
        <hr>
        <p><em>Dashboard Bibliom√©trico Avan√ßado - Todas as 9 an√°lises cient√≠ficas inclu√≠das!</em></p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()